{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Competition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# You may need to change the path\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "subNumber = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     id                                        description  ratingCategory\n0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n2   655  \\nThis release is a port version of Amrut’s In...               1\n3   555  \\nThis 41 year old single cask was aged in a s...               1\n4  1965  \\nQuite herbal on the nose, with aromas of dri...               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>description</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1321</td>\n      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3861</td>\n      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>655</td>\n      <td>\\nThis release is a port version of Amrut’s In...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>555</td>\n      <td>\\nThis 41 year old single cask was aged in a s...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1965</td>\n      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "#\n",
    "# randomforest_pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4))),\n",
    "#                  ('randomforest', RandomForestClassifier())])\n",
    "#\n",
    "# xgboost_pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4))),\n",
    "#                  ('model', XGBClassifier(seed=1337))])\n",
    "#\n",
    "# randomforest_pipeline_hardcoded = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4),\n",
    "#                                                                      max_df=1.0, min_df=.02, max_features=750)),\n",
    "#                  ('randomforest', RandomForestClassifier(max_depth=20, n_estimators=100))])\n",
    "#\n",
    "# xgboost_pipeline_hardcoded = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4), max_df=0.5,\n",
    "#                                                                 max_features=775, min_df=0.01)),\n",
    "#                  ('model', XGBClassifier(seed=1337, colsample_bytree=0.28, gamma=2.75, learning_rate=0.22,\n",
    "#                                          max_depth=60, min_child_leaf=7, min_child_weight=1, n_estimators=275,\n",
    "#                                          scale_pos_weight=100, subsample=0.8))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-139-e016f7300eec>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     77\u001B[0m         \u001B[0mprevious_score\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 79\u001B[1;33m         \u001B[0mxgboost_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'description'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'ratingCategory'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mreport_step_xgboost\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     80\u001B[0m         \u001B[0mxgboost_pipeline_train_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxgboost_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'description'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m         \u001B[0mxgboost_pipeline_test_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxgboost_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'description'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.virtualenvs\\Lambda_Unit4\\lib\\site-packages\\skopt\\searchcv.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, callback)\u001B[0m\n\u001B[0;32m    678\u001B[0m                 optim_result = self._step(\n\u001B[0;32m    679\u001B[0m                     \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msearch_space\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 680\u001B[1;33m                     \u001B[0mgroups\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgroups\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_points\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_points_adjusted\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m                 )\n\u001B[0;32m    682\u001B[0m                 \u001B[0mn_iter\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[0mn_points\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.virtualenvs\\Lambda_Unit4\\lib\\site-packages\\skopt\\searchcv.py\u001B[0m in \u001B[0;36m_step\u001B[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[1;31m# convert parameters to python native types\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m         \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    556\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m         \u001B[1;31m# make lists into dictionaries\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.virtualenvs\\Lambda_Unit4\\lib\\site-packages\\skopt\\searchcv.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[1;31m# convert parameters to python native types\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m         \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    556\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m         \u001B[1;31m# make lists into dictionaries\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\.virtualenvs\\Lambda_Unit4\\lib\\site-packages\\skopt\\searchcv.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[1;31m# convert parameters to python native types\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m         \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    556\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m         \u001B[1;31m# make lists into dictionaries\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignore warnings generated by bayes search\n",
    "\n",
    "tune = False\n",
    "xgboost_tune = False\n",
    "\n",
    "if tune:\n",
    "    parameters = {\n",
    "        'vect__max_df': ( 0.75, 1.0),\n",
    "        'vect__min_df': (.02, .03),\n",
    "        'vect__max_features': (700, 750, 800),\n",
    "        'randomforest__n_estimators':(100, 125, 150),\n",
    "        'randomforest__max_depth':(20, 25, 30)\n",
    "    }\n",
    "\n",
    "    xgboost_distributions = {\n",
    "        # 'vect__max_df': (0.5, 1.0),\n",
    "        # 'vect__min_df': (.01, .02, .03, .04, .05, .10),\n",
    "        # 'vect__max_features': (725, 750, 775),\n",
    "        'model__n_estimators': [250, 275, 300, 325, 350],\n",
    "        'model__max_depth': [50, 60, 70, 75, 80, 85, 95, 100],\n",
    "        'model__learning_rate': [0.22, 0.23, 0.24, 0.25, 0.26],\n",
    "        'model__min_child_leaf':[6, 7, 8],\n",
    "        'model__min_child_weight': [1, 2, 3, 5, 7, 9, 12, 15],\n",
    "        'model__colsample_bytree':[0.28, 0.30, 0.32],\n",
    "        'model__subsample':[0.8, 0.9, 1],\n",
    "        'model__gamma':[2.5, 2.75, 3, 3.25, 3.50],\n",
    "        'model__scale_pos_weight': [100, 110, 120, 130, 140, 150]\n",
    "        'vect__max_df': (0.5, 1.0),\n",
    "        'vect__min_df': (.01, .02, .03, .04, .05, .10),\n",
    "     }\n",
    "\n",
    "    randomforest_pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4))),\n",
    "                 ('randomforest', RandomForestClassifier())])\n",
    "\n",
    "    xgboost_pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4))),\n",
    "                 ('model', XGBClassifier(seed=1337))])\n",
    "\n",
    "    def report_step_xgboost(optim_result):\n",
    "        global previous_score\n",
    "        global i\n",
    "        global total_i\n",
    "        score = xgboost_search.best_score_\n",
    "        print(\"XGboost best score: %s\" % score)\n",
    "        if score > previous_score:\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "        print(\"Iterations since improvement: \", i)\n",
    "        total_i += 1\n",
    "        print(\"Total iterations: \", total_i)\n",
    "        if i > 5:\n",
    "            print(\"Over 5 iterations with no improvement, aborting...\")\n",
    "            return True\n",
    "        previous_score = score\n",
    "        print(\"--------------------------------------\")\n",
    "\n",
    "    xgboost_search = BayesSearchCV(\n",
    "        xgboost_pipeline,\n",
    "        search_spaces=xgboost_distributions,\n",
    "        n_iter=1000,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        random_state=1337,\n",
    "        n_points=5,\n",
    "        n_jobs=15\n",
    "    )\n",
    "\n",
    "    if xgboost_tune:\n",
    "        i = 0\n",
    "        total_i = 0\n",
    "        previous_score = 0\n",
    "\n",
    "        xgboost_search.fit(train['description'], train['ratingCategory'], callback=report_step_xgboost)\n",
    "        xgboost_pipeline_train_pred = xgboost_search.predict(train['description'])\n",
    "        xgboost_pipeline_test_pred = xgboost_search.predict(test['description'])\n",
    "\n",
    "else:\n",
    "    xgboost_pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english', ngram_range=(1,4), max_df=0.5,\n",
    "                                                                max_features=775, min_df=0.01)),\n",
    "                 ('model', XGBClassifier(seed=1337, colsample_bytree=0.28, gamma=2.75, learning_rate=0.22,\n",
    "                                         max_depth=60, min_child_leaf=7, min_child_weight=1, n_estimators=275,\n",
    "                                         scale_pos_weight=100, subsample=0.8, n_jobs=15))])\n",
    "\n",
    "    xgboost_pipeline.fit(train['description'], train['ratingCategory'])\n",
    "    xgboost_pipeline_train_pred = xgboost_pipeline.predict(train['description'])\n",
    "    xgboost_pipeline_test_pred = xgboost_pipeline.predict(test['description'])\n",
    "\n",
    "\n",
    "\n",
    "# parameters = {\n",
    "#     'vect__max_df': (0.75, 1.0),\n",
    "#     'clf__max_depth':(5,10,15,20)\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(randomforest_pipeline,parameters, cv=5, n_jobs=15, verbose=3)\n",
    "# grid_search.fit(train['description'], train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost cross val score: 0.7418649540779223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "if tune:\n",
    "    if xgboost_tune:\n",
    "        print(\"XGboost best score:\", xgboost_search.best_score_)\n",
    "        print(\"XGboost best params:\", xgboost_search.best_params_)\n",
    "else:\n",
    "    print(\"XGboost cross val score:\", np.mean(cross_val_score(xgboost_pipeline, train['description'], train['ratingCategory'], cv=5,\n",
    "                                            n_jobs=14)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('vect',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=750,\n                                 min_df=0.02, ngram_range=(1, 4), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words='english', strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pat...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=20, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforest_pipeline_hardcoded.fit(train['description'], train['ratingCategory'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7230283732302268\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# import numpy as np\n",
    "#\n",
    "# print(np.mean(cross_val_score(randomforest_pipeline_hardcoded, train['description'], train['ratingCategory'], cv=5,\n",
    "#                                                 n_jobs=14)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "# pred = xgboost_search.predict(test['description'])\n",
    "pred = xgboost_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     id  ratingCategory\n0  3461               1\n1  2604               1\n2  3341               0\n3  3764               1\n4  2306               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import randint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_word_vectors(train['description'])\n",
    "X_test = get_word_vectors(test['description'])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:27:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { min_child_leaf, scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignore warnings generated by bayes search\n",
    "\n",
    "tune = False\n",
    "xgboost_tune = False\n",
    "forest_tune = False\n",
    "svc_tune = False\n",
    "\n",
    "if tune:\n",
    "    parameters = {\n",
    "        # 'vect__max_df': ( 0.75, 0.85, 0.95, 1.0),\n",
    "        # 'vect__min_df': (.02, .03, .05, .07),\n",
    "        'max_features': (225, 250, 275, 300),\n",
    "        'n_estimators':(115, 125, 140),\n",
    "        'max_depth':(215, 225, 240),\n",
    "        'min_samples_leaf': [8, 9, 10, 11, 12, 13]\n",
    "    }\n",
    "\n",
    "    xgboost_distributions = {\n",
    "        # 'vect__max_df': (0.5, 1.0),\n",
    "        # 'vect__min_df': (.01, .02, .03, .04, .05, .10),\n",
    "        # 'vect__max_features': (725, 750, 775),\n",
    "        'n_estimators': [50, 100, 200, 250, 300, 350, 400, 450, 500],\n",
    "        'max_depth': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60],\n",
    "        'learning_rate': [0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24],\n",
    "        'min_child_leaf':[3, 5, 7, 9, 11],\n",
    "        'min_child_weight': [10, 15, 20, 25, 30, 35, 40],\n",
    "        'colsample_bytree':[0.10, 0.15, 0.20, 0.25, 0.30, 0.35],\n",
    "        'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        'gamma':[1, 2, 3, 4, 5, 10, 20, 30, 40, 50],\n",
    "        # 'scale_pos_weight': [50, 75, 100]\n",
    "     }\n",
    "\n",
    "    svc_distributions = {\n",
    "    'kernel': ['poly'],\n",
    "    'degree':[1, 2, 3],\n",
    "    'C':[10],\n",
    "    'gamma': [0.12, 0.14, 0.15, 0.16, 0.18]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    randomforest = RandomForestClassifier(random_state=1337)\n",
    "    xgboost = XGBClassifier(seed=1337)\n",
    "    svc = SVC(random_state=1337)\n",
    "\n",
    "\n",
    "    def report_step_forest(optim_result):\n",
    "        global previous_score\n",
    "        global i\n",
    "        global total_i\n",
    "        score = forest_search.best_score_\n",
    "        print(\"Random Forest best score: %s\" % score)\n",
    "        if score > previous_score:\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "        print(\"Iterations since improvement: \", i)\n",
    "        total_i += 1\n",
    "        print(\"Total iterations: \", total_i)\n",
    "        if i > 2:\n",
    "            print(\"Over 2 iterations with no improvement, aborting...\")\n",
    "            return True\n",
    "        previous_score = score\n",
    "\n",
    "    def report_step_xgboost(optim_result):\n",
    "        global previous_score\n",
    "        global i\n",
    "        global total_i\n",
    "        score = xgboost_search.best_score_\n",
    "        best_params = xgboost_search.best_params_\n",
    "        print(\"XGboost best score: %s\" % score)\n",
    "        print(\"XGboost best params: %s\" % best_params)\n",
    "        if score > previous_score:\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "        print(\"Iterations since improvement: \", i)\n",
    "        total_i += 1\n",
    "        print(\"Total iterations: \", total_i)\n",
    "        if i > 10:\n",
    "            print(\"Over 10 iterations with no improvement, aborting...\")\n",
    "            return True\n",
    "        previous_score = score\n",
    "        print(\"--------------------------------------\")\n",
    "\n",
    "    xgboost_search = BayesSearchCV(\n",
    "        xgboost,\n",
    "        search_spaces=xgboost_distributions,\n",
    "        n_iter=1000,\n",
    "        cv=5,\n",
    "        # scoring='accuracy',\n",
    "        scoring='neg_log_loss',\n",
    "        random_state=1337,\n",
    "        n_points=5,\n",
    "        n_jobs=15\n",
    "    )\n",
    "\n",
    "    forest_search = BayesSearchCV(\n",
    "        randomforest,\n",
    "        search_spaces=parameters,\n",
    "        n_iter=1000,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        random_state=1337,\n",
    "        n_points=5,\n",
    "        n_jobs=15\n",
    "    )\n",
    "\n",
    "    svc_search = GridSearchCV(\n",
    "        svc,\n",
    "        param_grid=svc_distributions,\n",
    "        cv=5,\n",
    "        scoring='accuracy', #good out of the box scoring metric for multiclass hyperparameter tuning\n",
    "        verbose=10,\n",
    "        n_jobs=15\n",
    "    )\n",
    "\n",
    "\n",
    "    if forest_tune:\n",
    "        i = 0\n",
    "        total_i = 0\n",
    "        previous_score = 0\n",
    "\n",
    "        forest_search.fit(X_train, train['ratingCategory'], callback=report_step_forest)\n",
    "        forest_train_pred = forest_search.predict(X_train)\n",
    "        forest_test_pred = forest_search.predict(X_test)\n",
    "\n",
    "    if xgboost_tune:\n",
    "        i = 0\n",
    "        total_i = 0\n",
    "        previous_score = 0\n",
    "\n",
    "        xgboost_search.fit(X_train, train['ratingCategory'], callback=report_step_xgboost)\n",
    "        xgboost_train_pred = xgboost_search.predict(X_train)\n",
    "        xgboost_test_pred = xgboost_search.predict(X_test)\n",
    "\n",
    "    if svc_tune:\n",
    "        svc_search.fit(X_train, train['ratingCategory'])\n",
    "        svc_train_pred = svc_search.predict(X_train)\n",
    "        svc_test_pred = svc_search.predict(X_test)\n",
    "\n",
    "else:\n",
    "\n",
    "    randomforest = RandomForestClassifier(random_state=1337, max_depth=225, max_features=250,\n",
    "                                                   min_samples_leaf=13, n_estimators=125, n_jobs=15)\n",
    "    xgboost = XGBClassifier(seed=1337, colsample_bytree=0.1, gamma=4, learning_rate=0.08, max_depth=50,\n",
    "                            min_child_leaf=6, min_child_weight=25, n_estimators=400, scale_pos_weight=130,\n",
    "                            subsample=0.9, n_jobs=15)\n",
    "\n",
    "    logistic = LogisticRegressionCV(max_iter=300, n_jobs=15)\n",
    "\n",
    "    svc = SVC(random_state=1337, C=10, degree=2, gamma=0.15, kernel='poly')\n",
    "\n",
    "    randomforest.fit(X_train, train['ratingCategory'])\n",
    "    forest_train_pred = randomforest.predict(X_train)\n",
    "    forest_test_pred = randomforest.predict(X_test)\n",
    "\n",
    "    xgboost.fit(X_train, train['ratingCategory'])\n",
    "    xgboost_train_pred = xgboost.predict(X_train)\n",
    "    xgboost_test_pred = xgboost.predict(X_test)\n",
    "\n",
    "    logistic.fit(X_train, train['ratingCategory'])\n",
    "    logistic_train_pred = logistic.predict(X_train)\n",
    "    logistic_test_pred = logistic.predict(X_test)\n",
    "\n",
    "    svc.fit(X_train, train['ratingCategory'])\n",
    "    svc_train_pred = svc.predict(X_train)\n",
    "    svc_test_pred = svc.predict(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# xgboost_test = xgboost.fit(X_train, train['ratingCategory'])\n",
    "# randomforest_test = randomforest_pipeline.fit(X_train, train['ratingCategory'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost cross val score: 0.7487175036585036\n",
      "Random forest cross val score: 0.7386849736497952\n",
      "Logistic regression cross val score: 0.7514135740214811\n",
      "SVC cross val score: 0.7604654155431793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "if tune:\n",
    "    if xgboost_tune:\n",
    "        print(\"XGboost best score:\", xgboost_search.best_score_)\n",
    "        print(\"XGboost best params:\", xgboost_search.best_params_)\n",
    "\n",
    "    if forest_tune:\n",
    "        print(\"Random forest best score:\", forest_search.best_score_)\n",
    "        print(\"Random forest best params:\", forest_search.best_params_)\n",
    "\n",
    "    if svc_tune:\n",
    "        print(\"SVC best score:\", svc_search.best_score_)\n",
    "        print(\"SVC best params:\", svc_search.best_params_)\n",
    "else:\n",
    "    print(\"XGboost cross val score:\", np.mean(cross_val_score(xgboost, X_train, train['ratingCategory'], cv=5,\n",
    "                                                n_jobs=14)))\n",
    "\n",
    "    print(\"Random forest cross val score:\", np.mean(cross_val_score(randomforest, X_train, train['ratingCategory'], cv=5,\n",
    "                                                n_jobs=14)))\n",
    "\n",
    "    print(\"Logistic regression cross val score:\", np.mean(cross_val_score(logistic, X_train, train['ratingCategory'], cv=5,\n",
    "                                            n_jobs=14)))\n",
    "\n",
    "    print(\"SVC cross val score:\", np.mean(cross_val_score(svc, X_train, train['ratingCategory'], cv=5,\n",
    "                                            n_jobs=14)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# type(logistic_test_pred)\n",
    "\n",
    "models_list = [logistic_test_pred, forest_test_pred, xgboost_test_pred]\n",
    "\n",
    "new_df = pd.DataFrame(models_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RangeIndex' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-96-64c9b8931dfa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mnew_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'RangeIndex' object is not callable"
     ]
    }
   ],
   "source": [
    "new_df.columns()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "      0     1     2     3     4     5     6     7     8     9     ...  1012  \\\n0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n1017   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n1018   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n1019   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n1020   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n1021   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n\n      1013  1014  1015  1016  1017  1018  1019  1020  1021  \n0      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n2      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n3      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n4      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n1017   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1018   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1019   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1020   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n1021   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n\n[1022 rows x 1022 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1012</th>\n      <th>1013</th>\n      <th>1014</th>\n      <th>1015</th>\n      <th>1016</th>\n      <th>1017</th>\n      <th>1018</th>\n      <th>1019</th>\n      <th>1020</th>\n      <th>1021</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1017</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1019</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1020</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1022 rows × 1022 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.corr(method='pearson')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "#\n",
    "# df = pd.DataFrame(X_tfidf.todense(), columns=vicktor.get_feature_names())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfc = RandomForestClassifier()\n",
    "# rfc.fit(X, train['ratingCategory'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rfc.score(X,train['ratingCategory'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "300"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(X[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = xgboost_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     id  ratingCategory\n0  3461               1\n1  2604               1\n2  3341               1\n3  3764               1\n4  2306               1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ratingCategory</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3461</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2604</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3341</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3764</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2306</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./data/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"?\n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What is sentiment Analysis?\n",
    "Sentiment analysis is trying to find the emotion behind a word. While words can be counted and compared, without looking\n",
    "at the sentiment behind the word it does not paint the whole picture.\n",
    "\n",
    "# Is Document Classification different than \"Sentiment Analysis\"?\n",
    "Yes, they are not the same thing. Sentiment analysis has to do with understanding what a chunk of text means. Document\n",
    "classification is used to group text together based on similarity.\n",
    "\n",
    "# How do create labeled sentiment data?\n",
    "One technique that can be used is textblob.\n",
    "\n",
    "# What are common applications of sentiment analysis?\n",
    "It commonly is used to gauge customers opinions of a new product.\n",
    "\n",
    "# Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "Bag of words approaches can often word better than word embeddings when the scope of the text is limited to a paticular\n",
    "domain. This is because unless you create your own neural network for the embeddings, you are using a pretrained model\n",
    "on generalized data. If you were to create your own model for the embeddings, you would need a sufficient amount of data\n",
    "to train it.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "u4-s1-nlp",
   "language": "python",
   "display_name": "U4-S1-NLP (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}