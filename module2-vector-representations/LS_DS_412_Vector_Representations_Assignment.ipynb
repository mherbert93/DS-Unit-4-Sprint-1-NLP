{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def clean_listing(description):\n",
    "\n",
    "    soup = BeautifulSoup(description)\n",
    "\n",
    "    return soup.get_text()\n",
    "\n",
    "def tokenize(document):\n",
    "\n",
    "    doc = nlp(document)\n",
    "\n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) and (token.is_digit == False)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read through the documentation to accomplish this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/job_listings.csv')\n",
    "df.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "df['cleaned_description'] = df['description'].apply(clean_listing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_description'][0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df['cleaned_description'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "## df['tokens'][1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "count_vectorize = CountVectorizer(stop_words='english', max_features=1000, max_df=.97, min_df=.05, tokenizer=tokenize,\n",
    "                                  ngram_range=(1, 4))\n",
    "\n",
    "dtm = count_vectorize.fit_transform(df['cleaned_description'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=count_vectorize.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "   $  +  + year  + year experience  \\xe2\\x80\\x93  ability  ability work  able  \\\n0  0  0       0                  0             0        1             0     0   \n1  0  1       1                  0             0        1             0     0   \n2  0  0       0                  0             0        0             0     0   \n3  3  0       0                  0             0        0             0     0   \n4  0  1       1                  0             1        0             0     0   \n\n   academic  accelerate  ...  write communication skill  write verbal  \\\n0         0           0  ...                          0             0   \n1         0           0  ...                          0             0   \n2         0           0  ...                          0             0   \n3         0           0  ...                          0             0   \n4         0           0  ...                          0             0   \n\n   write verbal communication  year  year experience  year relevant  \\\n0                           0     0                0              0   \n1                           0     1                0              0   \n2                           0     0                0              0   \n3                           0     1                0              0   \n4                           0     1                0              0   \n\n   year work  years\\xe2\\x80\\x99  york  you\\xe2\\x80\\x99ll  \n0          0                  0     0                  0  \n1          0                  0     0                  0  \n2          0                  0     0                  0  \n3          0                  0     0                  0  \n4          0                  0     0                  0  \n\n[5 rows x 1000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>$</th>\n      <th>+</th>\n      <th>+ year</th>\n      <th>+ year experience</th>\n      <th>\\xe2\\x80\\x93</th>\n      <th>ability</th>\n      <th>ability work</th>\n      <th>able</th>\n      <th>academic</th>\n      <th>accelerate</th>\n      <th>...</th>\n      <th>write communication skill</th>\n      <th>write verbal</th>\n      <th>write verbal communication</th>\n      <th>year</th>\n      <th>year experience</th>\n      <th>year relevant</th>\n      <th>year work</th>\n      <th>years\\xe2\\x80\\x99</th>\n      <th>york</th>\n      <th>you\\xe2\\x80\\x99ll</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1000 columns</p>\n</div>"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "dtm_counts = dtm.sum(axis=0).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAeyUlEQVR4nO3beXxU9b3/8c9ZZl8zM9km2yQhZIOQCCigUrWVatWqaPWh8qtaa/21Xruora23v1t/3p9ae2u9tj9bf+3Pbi6tS91QKyooBcEFBCX7RtZJZjL7vp1z7h8YRCBBe8l3onk//yJnzvI938BrzjkzcIqiEAAAsMHnewAAAAsJogsAwBCiCwDAEKILAMAQogsAwJA424utN9y7i9VAYP4pfaIv30OY11a/OpbvIcwrD208Pd9DmDf6fvS9FTO9hitdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYWVHRzybjg2b25MN/jAICFa2FFNxUXAp1vFeV7HACwcIn5HgBL7u3PlmdjIU33wz9tMpTVRkSdMRsZ3GeTZYkzVzWGyk69wE1ENPDMb2qz8YhakXK8fckaT9EJp/uIiN5/4JY2W8NKb2x8wCxotFLpqnPG3Ds2VuTiEXXpmnNHCuqXh/N7hgAw3y2oK13nKeePqYzWdMOGH3aaKusjmbBPu/iy73c1XH5LZ9I3ro8MdxmJiCrXbRhquOKWrsWX3dzp79hZnE1EBSIiJZfljWWLog1X3NLFqzTSxJsvli266IbeqrOv7Pe880pZfs8OAD4NFlR0DxUd7jbH3APmnkfubup59GdNmbBfmw56tURE3t2bi7sfvqup77FfNOYSEVXKP6klIuJ4QbEsWhYhItLaipOG0uooL4iKvqgymY2H1fk8n4Xqtak/LU1L8Vnv2D7OOp9Wbz4yaH/q1j2Vx1onOJ5QTf/8+M27q9ydIe3cj46t0I5tds8Tj846F0cT3bvb4t/0QslcjOloPpN/ET8ehQqXrZ0oOuEM36FLI0Odprh7wFR3yY3dgloj9z5+b70iZQ+8OfG8wnHcB2tyxAuiQkTE8TwpiswRwDz0/vPjjpJ6S7KgTJ8lIrrk58uH8z2m+cTUujxMRMweDS6o6AoanSRnMzwRkamqMeJ5e5PT3rw6IGh0cjriV/G8qEjppMCrdZKg1sjJqXFtyuc25HvcnzXxXEi9K/h8nUVVFIvkpowG0ZYo1zb4+uO7yrJySlxqOWPQKBak3w+/6kpKMY3AiXKz+XPDVlVxMi0lhD3hTTVZOaUyqxzxQ/c7kmi3jSQ7ihVF5swqR3yp+fPDPDd/b+b+dO3O2qg3pc5lZX7lJS7PyVfV+v59xQttJ6yv9A7snLKIakG+4v4T+y0lutz7L45btv//vlIpp/Basyp3yc+XD1pKdLnpfSUjWf7+C19v/u7fP98uqnklGc7w91/4evMZ/9Iw5umL6J/+1z01opqXr3tsbdcfr9m5eN1NTaOuFfZEx8tu85b7e8oUWeF0ZlXu2kdO7c3HXIw/+JvaXDSiVnI53nLSGk/Bqaf7Bn5yS5t5+UneRH+PhRNF2Xnltf2ixZqLvveuJfj65lJFlnhBq8uVXH7loGixHpwLKZnkR+67u9l184/bOVFUpESCH7nvZ82u7/+4PfiPLYWRd98p5DheUTkcKeeV1w6Gdmyzp8dHDcVfuXwksuutguDWzU7iOIXXaKSK62/sOd7nuqCiq9KbJH1ReazroTubjeV1YcuiZYHex+9tICLiVWq5at2G/ZbalrC/Y2dh18N3NWnM9pTW4Ywfa7/wySXlmHaZ4cxBi1g4vN3/eKM71WtfY7u4eyLVZx2M7y7V8IaMSbQnVhZ8ecCbHjLtC2+pPtVxWWdv7E2nVVUcazCtmZhI9VsmUv0OIqJIdko7mRqwrbFd3M1zgvJe+NXK0WSHvUq/1J/vc53JRT89Ycho10iZRI77zcVbm5adWxbMpWW+otUWO+fWpeMbb3+//K1H9heuu6lponaVI7b0LGc3x3O0408Djtcf6C05/7ZlY9P70plVcsWygmjHJrdl2XnloXefHrXVrS0OnrC+MrjrieGi6cgeevyINyW+cGe76+rfr+4urDFlYv60wH4WDii+dMOQaDRJcibNjf7qniZT64qgks3y2ipXrPDL68e9zzxRHtqxrdBx9nkT+kWLY8aWtm6O4yi4/XVHYPOmkqL1lx6cC0Gnk7UVrmh0316LuW1FKLL7LZuhvjHIiaIS2rmtxPWDf9vHq1SKFI8fcb7BrZtLnVdf16uy2bNHe/14WFDRJSKqPvfr+w/9uWTlOu/h6yxa/y99R9u25X/evWf6z9PfdDjaa3BsWt6QtqqKk0REBtGatKvLIxzHkVlVmBiI73ampLimzXpWPxFRkcYVbY+8LmbklBDKekzTy0u1i8IdkdclIqKpzIgpmgvo3/A/3khEJCsSr+Y/vBKcj7Y/2F/cu81jJSKK+dIq70BUy4ucsvQsZ5iIyNlsiQ/s9JmJiILjCfVfvvNOeTyQUck5mTeX6NKH72/5xZVT238/ULLsvPLQe8+POc6/bdnQbMcf2uU3lC+1RgtrTBkiIqNdIx33k/yYgls3Fyd6uqxERLloRJXxTmqJFxRjS1uYiEhTVhFP9veaiYiygYDa99Dvy6V4TKVIEi9arEfMheXE1VPBf2wpMbetCEX37HYUrb9kiIhI7ShKTj78+2pD45KQsfWE0OHbacorY57HH3EZmluCptblwbk41wUXXZgfeI5Xpv/MERHPCQeejxNHCskcRx++fsh6Ryw7SCGuRFvrbzavHZ+L8R5vPVs9pqFdftN1f13brTGI8m8v21afTck8L3AKxx/4eIDjOZKlA58VvHhne+WqDdWTLeeUh3u2ekxbH+h1Hr7PRWuK4i/e1a7p/YfHqMgKV7bEmpp1EIpyYPLzLN7daUrtHzBVXH9jN6/RyKO/vrdeyWZ5TvjwMxSO50mRJY6IaGrj3yqta9ZOmlqXh+PdnabAlk1HzIW+rj4+tfEpTbyn00iKzGnLK1NERGXXfqsv0dNtinXuswb/scVZddOt7YduV3LphpHEQJ8h3tVuGf3Vz5srbri5QzSZjuub0fx94AULmlVVHB1LdtmJiLzpYZOK0+RUvFa2qoqj48luOxHRRKrfnFOyAhGRQ1MZmUoPF6SkmEhElJYTQjwXmrffKElFs4LGKEoagyhPdIe1kz3hWT87SMdzgqVElyUi2vvsqH2m9ZacVeZ/+sd7a1rOKT/4AbFKJ0jpWPaIW2XXSkd87P2QaWowqiYiytfjBTmZFHitTuI1GjntHtemJ2b/HEVOpwXRWpAlIorsfnvGuTC2tPk9T/6lxtS63EdEpMgyZf1+taGxOVp0/sVjcjotyKnUR84545nU6Gvr4oXnXujmdbpcNuA/7n+HcKUL89Ji0yr3e+FXXf/wPdokcKK81HLGfiKixcZV7j3hTTXbfH9ttKqKYxpenyEisqgKU7WG5ePvBDcuVkghjnilyXzKiIGsmfyeydE1faE0vPuJ4cJfnrulqaBcnyqpt8z62cHab9S5n/zBu7UGhybjbLLEwxNJzdHWW76+0r/9wf6y5esrA9PLWr9c4Xvxrvaql+/plK97bG3X9HJzkTb3pR8tGfrrd3ctUhSF9BZ19usPn3LUR2tzybCkJRx+Z2fh8D13Nans9pSmdPbPUWynneme/OtDtaLRlNGUVcRz4eBR58K84iR/aOuWMvOKVQfmQpY5z2MPVcvptEBEnOXE1R7BYPjIVezUC8+U54IBDRFx2qrqiLayKnmcTvMgTlFmvmNrveHeXcf7gPDpUfoE839/nyqrXx079kqMvfv0SEHPax7rZb9cuf/Yax9fD208nfUhZxXZ/XZBvLPdWvo/vsZ8Lvp+9L0VM72GK12Az4in/nVPxf63fZYr7j9pwb9bep54tCI52G8p/erX591cILoAnxHr72gbJaLRfI9jPij+yuXzdi7wQRoAAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ+JsL5a+7GE1DgCABQFXugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADM36PV1Y2OSK4nwPYV574+r5OT9931Pl58BVyfwc91MGV7oAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAwhugAADCG6RNTl3ezs820rnun18Ui7NZya1LIcEwB8NiG6H4M31meNpr26fI8DAD79xHwPIF96pl4vmYx2OTSiMaMSdFmzpjixP/C2Yzyyr1BWZE6nMqfbnBfuDyXdOn9iyBpKuU37A2+VtjkvHJiKD5oOX0/k1XK+zwk+FIwO6cd9e+1Lqi8YzfdY4JMLb9phzwyOGwq/+ZWRf2Zb/QmNEVVhQXYuxvbftSCjG0iM6j2xXtvJrms6FUWiN4b/0GTWFCec5uZgte1EHxFRp/cV53Bwl6PWvsZr17tChYbacLmlJUhEpBJ0uaOtl89zgo8qMLkSBSZXIt/jgI9SJJk4YW5vsGPb9zo0VaVJRHceCSRHjIWGmtD01alDXx0iIoqkJnV9/m1lOTkjSEpWsOkqwkfb/uOuB8dfTkrze/oerUlnY2qFFK665GS3XmtP94y8VCnJWZ7nBWVl/dU9odioYcizo3hl/VX9OSnNdww9WxlP+nQKyVx16Vq3094SGva8ZfeFe6ySnONTmbDGYVkUaqo6b4yIaDLQYR5wv1amKAqnEnW5kxq/3jvTfvI9J/NFxj2l9vzsT3XqqtJ4ZsyjVxXZUkXfvmxo7OZ7mw1rlvlSnYNm0+dP9JKicOEXtpcQKZxuyaKQ42vnjxMRhV/aYY/8/Y1S3mzIqopsKU4UFCIiz38+6tK31YdNn1seJCIauvq2NtcfbttDRBR4/JXi+Jv77BzPkba5JqypKU9kx7z6qd88WcOpRNn5f67v4rVqJX+zcqQFGd0DuCOWtHtfqm4rvaDfqitLDgd32QPJUdPRtvy468Hx5wl2mtUqY3Zlw9X9RESZXELY2fGbpqU1Fw3YTK5ENpfkhcMe9fSNvVpqM1VHltVeMpTJJoQ3u/5fY5G1PkJEFEtO6Vc3f7NT4FTytvb7lriKT/bwvErpHnnRtbL+qm6DrjCTzsaE2fYjCho8WvpAbiqotX/t/CF9S13cc9+jrvDz2wqJiDiVKJfdcX1PdiqomvjJAw3OO67vEkyG3MTtv10c277Hqm2ojoef2+p03nF9l2DUS+6fPFCvriie9U4l9uY+c3JvT0HZHdd38zqNLIVjgmAxSpFX3yqyX3H2qLahel7e6SzI6Nr1VbF9ky+66uRTJxRF5nyJIWuZecmUJGd5rWjOyorETUS7bRrRkCUiEni1lJMzB++JZloP5p5Z70z2j2+p6Bx+vqzIWh9WiTpJrTJkbR88SlCJuiMCGIgOmX2RAeuw980SIiJZlrhEKqAmIrIaKyNqUS8REek1tlQiHdBkc0nBYiiPGnSFGSIijcoozbYfs6E0xebs5z/BYszoW+riRETGU9r8kU07i4iITKe2BYmI0j3DBk1dZVQsMOeIiAyrWwLJrv1GIqJDl+tXNgdyk75ZvzGU3NdvNp7c6uN1B970BMuB39N8tyCjW6ArTxQbFwfeGHqwWSOa0hZtaYyIqMa2yr1z9M+NWsGYMWgcCUnOCERETlNToMP7sms0vKe4rfTCgZnWg7ln0henVzVd1+kNdln6xreU2UyuCBF3zNvH1tpL+k36kvShy4KxEQPPiwe35TheURSZI1KOdiM0437gENxhE/fBj5xu+m7gk9/pczynkHxgO0VRSJEk7uC+Zvg9zWcLMrpERPWFp03WF542efjyGtuqqcOXOQzV8c9VX9cx/bNR45g62now95LpkEotGnIVRSsDgqCWx6fedWSyMXUgOqSf6fGCzeSKDHl2Fi9xXTDCcRwFYyO6AmNlcqZjFJiq4z2jm6riySn19OMFjcoofdL9LERSKKpOtvcbdEsWxeM73rNp6ypj2TGvfvp1bUN1PPCXTRW5UFQUTIZc/M19NvOZq7zaBtf0ckEw6OTErs4CdXlRkohIdBRk0vvH9abTVwTjb+y1kiRzRET6lsWR0LOvO02nrwwc+niB16olOZGetxdCCza68OkUSbh1fWOby4kj4klQGqu+NKwQUffI3ytlOcfzvCivrL+699Bt6srPdHcOP1f5RvuvmhQiTqs2p1fWX9U/0zG0alOuofJLQ3sHHlukKAqpRH32pMZr+j7pfhYisaggFd262+77w3NVqsKCtOWcU6eir+0qOvi6w5q1rj9jfOL23y0mUjhdc23YeEpriIjIct5a98RPHmjkzYasurIkQfKBuJq/uHrK8/M/Lxq75ZeN2gZXhFOrZCIiw0lLIukht3781l81coKgaJfUhh1XfXnceMoJPv+fNlYFHv37vPwgjVOUmcdzdv0PdzEcC8wzshn/H+TTqO97qrwcN+OeUnt+/ue6il/c1HHstT/bBi+/dcVMr+F/pAEAMIToAsBxoXYWZnCVe2yILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAEOILgAAQ4guAABDiC4AAENivgcA81ekzpjvIcDH4Fl12AJfXoYBHxOudAEAGEJ0AQAYmvXxQs9tZlbjgHmoeGO+RwDw2YMrXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF2Yt5IRr3rPxrua/zv7SMcCqq7XfldzvMYEc8v/1LPO+PvtpnyPYy6J+R4AwFzSGG3ZxtOvHcz3OODYFEki+/rz3fkex1xDdP9JI9/66VLnndd3iVZTLt9j+UxTFOrZ9kdXMjyp1xjsqcWnfHVo7wt3Ny/94ne71DpzLuId1A/v2Vix9Ivf6Qm6u4zD7z5XSUREHEdLzryhO5uKit1bH6xrO+9HHRM92+whd5dVlrJ8Oh7UWJ0NoZqVF48REQVG95nH2l9xKnKOUxsK0nVrNgyJap28/52/lYUme6wcxyvmotpIzYlfGfMOvF0w3rnZyXG8Iqg00tIvfrcnr3M0xyLbd9gi23cUkyRx6vKyuGn1Kp/v8Seryn5wYxfJMjf+H/c2Fl25YUCKRlXBv7/s5PW6XM7n12pcVdHCDZeNcDxP8ff2mUMvveJUpBwn2grSRVduGOJ1Onnkf92+1LC8zZfq6zebTl7tTXb1WPTNjWHTqhODqYFBvf/p5yqUTJbn9bpc0VevGBJtBdnxe+6r11SUx1KD+81KKi3YL71oSN/YEFMkifxPPFWe7B8wExGZTlzhs677gnem/eRrPhHdf4IiyfkewoKRjge01SsvGrKW1sd7t//Z5e56rXCmdSe6Xi9xLb9g2FpaH89lkjwvqo/4RSXDHv3Ss2/s5AWVvHfjXUtSDad5eFGtjHduLm3+wrd6BZVWHnnvxZLxjleLnY2neUMT3QWt593aznEcZdNxgYjI3bmltPH0b/Rqjfbs9LLPqvTYmDa+9z1b2c3f7eZEUfE+9GhldtKj1TfWhwJPPVumZLO8obXFr6msSCU6OlUZ94Sh7Ac3tqsKHZmJX/66Lvb2rgJdU0M09Mrm0tLvfKuX12rlwPMvlgQ3vVpsv+C8CSIiThTlsu9/r4eIKNnVYyEiUnI5zv+3ZyqLr7umX7RYctGdbxX4n9lYVvy1rw4RESmyzJX/8Oau2J69ltBLrzj1jQ294de2FuaCQU35j77fyQkCSdGocKz95MOCi27g8VeKOZWoFFx4unfqt09VZEc9Oue/f7M3vqvLFNu626FrXRwOv7C9hBSF0y1ZFHJcc/44EdHQVbe1mc5Y4Ul2DJptl589Nr0/OZXhJu/+4yLDiqag5ZxTfPk7s88mldaUsZbWx4mIHK7l/sne7UUzrWt0VMVG9jxfEfOPBByuE4Jate6I6JoKXRGVxiAREWlNjlQq5tfkMgkhFfVp9226r4GISFEkzlBQHhPUeonjRbnvjYeqCpyNYXtVa5iIyGCviPXvfNRlK28JOlwnBOfmzOeHZGePKeOe1I/ffU8jEZGSy/GC0ZizffncifGf/aKRBFEuu/zSken11c7SuLqkOENEZGhbFkgN7jdyKpWc8/m07ns+mF9J4jQV5bHpbUwnrjhiDjPuCU12yqeb/L8PLCYiUhSFBKPx4NWpobUlSESkrXbFA888ryYi+uBqeYoTDrwPCiaTlB4Z1c62n3xYcNHVNdXEwi9sKyYib2Z4Qq/kJF7J5rhU936jWGxLhZ7cXOa88/ouwWTITfzv3y6ObdtjNZ7aFlIyWV5dUZK0f/Xcg8+c5ESK9977SI3x5GV+87rV/jye1oLBERHH8QopChERyVL24IfBlcu+NGkrXxIOjLVb2l/+VWPj6df28oLqI+HleFE5+GeOVxRZ4khRyFRYHWn43DX7Dz9ey1k3dgXHO8y+kb0Fnv6dRUvWfbu3bs0VI2FPvyE41mHZ99I9zUvPuqlDrTNJc3fW+aRwhrZlfsdX1o8fujQXDIpyJsNzgsQp2SzPCcLRb/84jogU0tRUR0q+ceT8EhFxWs2R2yoKp3I4kmW33Nh9tG14UXXg98jzRLLMHdiGiIhTPrLiMfaTDwvu2wva+qpEZtRjkOJJnhMFRVNdFkv1DOnTfSMmXq+VNHWVUbHAnONEgQyrWwLJrv1GIiLiOTKu/ehVjfeehxcZT23zIbhzJ5uKqsOTvQYiIv/wuzajwxVT6yyZqG9IT0TkH3mvYHrdRHhSY7RXJiuXfWlSby2NJ0KT2o9zDHNxbTweGDMmQpMaIiIpm+bjIbcml0nyuUxCsFe1hmtWXjSajHj008exFC+Ku5af7xbU+lw67lcf/zOfH3SNDZFER2dBLhQWiYikaFTIeqfUU4885rKu+4Lb0Nri9z/5dPn0+pmJCUPG41Urskzxve/btDXVUe2i2nhmZMyYmTgwv3IqzWfG3ZrZjqt2lqakREJM9hz43Su5HJceGZ3196mtr4tE39hZqEgH3v+kaFT4Z/Yz1xbclS6nEhWxwJyOvPymQ1NbHlNXliaT+wZMOV9YIxYWZDJDE/qjbieKMid89D1KXVMWS77XZzF9/sQAx3FMxr/QaIy2lHfwHfv+XU9VaQy2tLPxtCmToyo++M7fXO7OLVmDrTw+va6767Wi6NSQmeN4RWtyJO0VLeF0Iqg61jHUOkuueuXFQ307Hq5R5BxHRFS+ZN24qNLJ3VsfXKTIOY4UooqWs0eJiIbffa48HQtoFFI4c2FNxGivSs7dDOSXpqI8VfDFM8cn739gsaIoxPGComtqCHE8r5hPXh1QJInG/+M/G+L7Okwcz5GmrCwWeOa58qzHq9O4qqLGlctDHM+T/dKLh7x/fLhGkQ7Mb8FZ68bVZc70TMflVCql6KoNA/6/PVOpPPm0oMgyZz55jUdTWZGaaRvLaWunst4pzdgddzdzgqAYV66Ysq77/NQn3c9c4xRFmfHFmr/cuYvhWJjxP/SCM77jfbv9mvOHNNVlSfePf92oqihOFH5j/Yj73x5oOPh44fbfLjafucprPKU1NHTVbW2uP962Z3of099eCP715VJFkrii6y8Zme2Yn0bFG2e9GIF5wrMq3yM4INHRaQpv2VpcesM3+/M9lnwb/PZNK2Z6bcE9XiAi0jbWRKVoQqVrromLdkuOU4mKdnFVTHRYs9b1Z4xP3P67xWM339usrixJGE9pDc22L8d160eVbI73PfhM+WzrAQAQLdArXfh4cKX76TBfrnThQ7jSBQCYJxBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhhBdAACGEF0AAIYQXQAAhjhFUfI9BgCABQNXugAADCG6AAAMIboAAAwhugAADCG6AAAMIboAAAz9FzTDMuUpD7qGAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "squarify.plot(sizes=dtm_counts, label=dtm_counts.index, alpha=.8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            $         +    + year  + year experience  \\xe2\\x80\\x93   ability  \\\n0    0.000000  0.000000  0.000000           0.000000      0.000000  0.082991   \n1    0.000000  0.042185  0.045750           0.000000      0.000000  0.038675   \n2    0.000000  0.000000  0.000000           0.000000      0.000000  0.000000   \n3    0.243795  0.000000  0.000000           0.000000      0.000000  0.000000   \n4    0.000000  0.227492  0.246719           0.000000      0.331556  0.000000   \n..        ...       ...       ...                ...           ...       ...   \n421  0.052954  0.063330  0.068682           0.098686      0.000000  0.058060   \n422  0.000000  0.000000  0.000000           0.000000      0.000000  0.000000   \n423  0.078354  0.000000  0.000000           0.000000      0.000000  0.000000   \n424  0.000000  0.000000  0.000000           0.000000      0.000000  0.000000   \n425  0.000000  0.000000  0.000000           0.000000      0.097926  0.000000   \n\n     ability work      able  academic  accelerate  ...  write verbal  \\\n0             0.0  0.000000       0.0    0.000000  ...           0.0   \n1             0.0  0.000000       0.0    0.000000  ...           0.0   \n2             0.0  0.000000       0.0    0.000000  ...           0.0   \n3             0.0  0.000000       0.0    0.000000  ...           0.0   \n4             0.0  0.000000       0.0    0.000000  ...           0.0   \n..            ...       ...       ...         ...  ...           ...   \n421           0.0  0.000000       0.0    0.000000  ...           0.0   \n422           0.0  0.000000       0.0    0.000000  ...           0.0   \n423           0.0  0.000000       0.0    0.000000  ...           0.0   \n424           0.0  0.094799       0.0    0.135596  ...           0.0   \n425           0.0  0.000000       0.0    0.000000  ...           0.0   \n\n     write verbal communication      year  year experience  year professional  \\\n0                           0.0  0.000000         0.000000                0.0   \n1                           0.0  0.030272         0.000000                0.0   \n2                           0.0  0.000000         0.000000                0.0   \n3                           0.0  0.034871         0.000000                0.0   \n4                           0.0  0.163249         0.000000                0.0   \n..                          ...       ...              ...                ...   \n421                         0.0  0.090891         0.074816                0.0   \n422                         0.0  0.000000         0.000000                0.0   \n423                         0.0  0.033622         0.000000                0.0   \n424                         0.0  0.025805         0.042482                0.0   \n425                         0.0  0.048216         0.000000                0.0   \n\n     year relevant  year work  years\\xe2\\x80\\x99     york  you\\xe2\\x80\\x99ll  \n0              0.0        0.0                0.0  0.00000           0.000000  \n1              0.0        0.0                0.0  0.00000           0.000000  \n2              0.0        0.0                0.0  0.00000           0.000000  \n3              0.0        0.0                0.0  0.00000           0.000000  \n4              0.0        0.0                0.0  0.00000           0.000000  \n..             ...        ...                ...      ...                ...  \n421            0.0        0.0                0.0  0.06345           0.047935  \n422            0.0        0.0                0.0  0.00000           0.000000  \n423            0.0        0.0                0.0  0.00000           0.000000  \n424            0.0        0.0                0.0  0.00000           0.000000  \n425            0.0        0.0                0.0  0.00000           0.000000  \n\n[426 rows x 1105 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>$</th>\n      <th>+</th>\n      <th>+ year</th>\n      <th>+ year experience</th>\n      <th>\\xe2\\x80\\x93</th>\n      <th>ability</th>\n      <th>ability work</th>\n      <th>able</th>\n      <th>academic</th>\n      <th>accelerate</th>\n      <th>...</th>\n      <th>write verbal</th>\n      <th>write verbal communication</th>\n      <th>year</th>\n      <th>year experience</th>\n      <th>year professional</th>\n      <th>year relevant</th>\n      <th>year work</th>\n      <th>years\\xe2\\x80\\x99</th>\n      <th>york</th>\n      <th>you\\xe2\\x80\\x99ll</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.082991</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.042185</td>\n      <td>0.045750</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.038675</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.030272</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.243795</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.034871</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.227492</td>\n      <td>0.246719</td>\n      <td>0.000000</td>\n      <td>0.331556</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.163249</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>0.052954</td>\n      <td>0.063330</td>\n      <td>0.068682</td>\n      <td>0.098686</td>\n      <td>0.000000</td>\n      <td>0.058060</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.090891</td>\n      <td>0.074816</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.06345</td>\n      <td>0.047935</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>0.078354</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.033622</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>424</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.094799</td>\n      <td>0.0</td>\n      <td>0.135596</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.025805</td>\n      <td>0.042482</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.097926</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.048216</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>426 rows × 1105 columns</p>\n</div>"
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                        ngram_range=(1, 4),\n",
    "                        max_df=.97,\n",
    "                        min_df=.05,\n",
    "                        tokenizer=tokenize)\n",
    "\n",
    "dtm = tfidf.fit_transform(df['cleaned_description'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n                 metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n                 radius=1.0)"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model = NearestNeighbors(n_neighbors=6, algorithm='kd_tree')\n",
    "model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "def recommendations(text):\n",
    "    text_transformed = tfidf.transform(text)\n",
    "    results = model.kneighbors(text_transformed.todense())\n",
    "\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.16087888, 1.17236512, 1.22079525, 1.22079525, 1.2253458 ,\n",
      "        1.23968927]]), array([[ 79, 327, 413, 153,  51, 338]], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "text = [\"\"\"\n",
    "Looking for a data scientist with experience in predictive modeling techniques such as linear regression, logistic regression, decision trees, SVC and neural networks.\n",
    "Experience with time series data is a plus.\n",
    "Skills:\n",
    "Python\n",
    "SQL\n",
    "Microsoft Access\n",
    "VBA\n",
    "\n",
    "Job location:\n",
    "Fully remote\n",
    "\"\"\"]\n",
    "\n",
    "print(recommendations(text))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"b'ContractAkraya is looking for a Data Scientist for one of our clients. If \"\n",
      " 'the job description below is a fit, please apply directly or call Swapnil at '\n",
      " '408-907-3201. If this position is not quite what you\\\\xe2\\\\x80\\\\x99 re '\n",
      " 'looking for, visit akraya.Com and submit a copy of your resume. Our '\n",
      " 'recruiters will get to work finding you a job that is a better match at one '\n",
      " 'of our many clients.\\\\n\\\\nPrimary Skills: Data Science, Hive/Impala/Hadoop, '\n",
      " 'Statistical and Data Mining, R, Python, Redshift/ S3/ Spark, Google '\n",
      " 'Analytics/ Adwords\\\\nDuration: 6+ Months, with possible extension\\\\nContract '\n",
      " 'Type: W2 Only\\\\n\\\\nTop Daily Responsibilities:\\\\nKnowledge and experience '\n",
      " 'with large data sets, event streams and distributed computing '\n",
      " '(Hive/Impala/Hadoop etc.)\\\\nAbility to gather requirements and develop '\n",
      " 'reports in tool selected by business and KPIT\\\\nSupport Data-Science and '\n",
      " 'other analytics as needed.\\\\nDevelop SQL queries and data sets\\\\nDevelop '\n",
      " 'business and client facing reports\\\\n\\\\nSkills a Top Candidate Should '\n",
      " 'Have:\\\\nWe\\\\xe2\\\\x80\\\\x99 re looking for someone with experience '\n",
      " 'manipulating data sets and building statistical models, have a '\n",
      " 'Master\\\\xe2\\\\x80\\\\x99 s or PHD in Statistics, Mathematics, Computer Science '\n",
      " 'or another quantitative field, and are familiar with software.\\\\nKnowledge '\n",
      " 'and experience in statistical and data mining techniques: GLM/Regression, '\n",
      " 'Random Forest, Boosting, Trees, text mining, social network analysis, '\n",
      " 'etc.\\\\nExperience querying databases and using statistical computer '\n",
      " 'languages: R, Python, SLQ, etc.\\\\nExperience using web services: Redshift, '\n",
      " 'S3, Spark, DigitalOcean, etc.\\\\nExperience creating and using advanced '\n",
      " 'machine learning algorithms and statistics: regression, simulation, scenario '\n",
      " 'analysis, modeling, clustering, decision trees, neural networks, '\n",
      " 'etc.\\\\nExperience analyzing data from 3rd party providers: Google Analytics, '\n",
      " 'Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, '\n",
      " 'etc.\\\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, '\n",
      " 'Hive, Spark, Gurobi, MySQL, etc.\\\\nExperience visualizing/presenting data '\n",
      " 'for stakeholders using: Periscope, Business Objects, D3, ggplot, '\n",
      " 'etc.\\\\n\\\\nDesired Skills:\\\\nStrong problem solving skills with an emphasis '\n",
      " 'on product development.\\\\nExperience using statistical computer languages '\n",
      " '(R, Python, SQL, etc.) to manipulate data and draw insights from large data '\n",
      " 'sets.\\\\nExperience working with and creating data architectures.\\\\nKnowledge '\n",
      " 'of a variety of machine learning techniques (clustering, decision tree '\n",
      " 'learning, artificial neural networks, etc.) and their real-world '\n",
      " 'advantages/drawbacks.\\\\nKnowledge of advanced statistical techniques and '\n",
      " 'concepts (regression, properties of distributions, statistical tests and '\n",
      " 'proper usage, etc.) and experience with applications.\\\\nExcellent written '\n",
      " 'and verbal communication skills for coordinating across teams.\\\\nA drive to '\n",
      " 'learn and master new technologies and techniques.\\\\n\\\\nSoft '\n",
      " 'Skills:\\\\nExcellent Communication Skills.\\\\nAbility to work with business to '\n",
      " 'gather report requirements\\\\nTeam player.\\\\n\\\\n\\\\nPlease apply directly with '\n",
      " 'your updated resume or call Swapnil at 408-907-3201\\\\n\\\\nAbout '\n",
      " 'Akraya\\\\nAkraya, Inc. Is an award-winning staffing firm that works with many '\n",
      " 'of the leading, technology-based companies around the world. We have been '\n",
      " 'ranked as one of the \\\\xe2\\\\x80\\\\x9c Best Staffing Firms to Temp '\n",
      " 'for\\\\xe2\\\\x80\\\\x9d by Staffing Industry Analysts on multiple occasions and '\n",
      " 'are a preferred staffing vendor within numerous staffing programs. Please '\n",
      " 'visit akraya.Com to search through all of our current openings or to submit '\n",
      " \"your resume to our recruiting team.'\")\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(df['cleaned_description'][79])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "name": "u4-s1-nlp",
   "language": "python",
   "display_name": "U4-S1-NLP (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}